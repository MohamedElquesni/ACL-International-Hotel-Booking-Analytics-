{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: International Hotel Booking Analytics\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements a comprehensive machine learning pipeline to predict the country group of hotel reviews based on user demographics, hotel characteristics, and review scores.\n",
    "\n",
    "**Dataset:**\n",
    "- Hotels Dataset: 25 hotels\n",
    "- Reviews Dataset: 50,000 reviews\n",
    "- Users Dataset: 2,000 users\n",
    "\n",
    "**Deadline:** October 22, 2025 at 11:59 PM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:08:34.921623Z",
     "start_time": "2025-10-10T22:08:34.917128Z"
    }
   },
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Model Explainability\n",
    "import shap\n",
    "# import lime\n",
    "\n",
    "# Database\n",
    "import sqlite3\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:13:34.560905Z",
     "start_time": "2025-10-10T22:13:34.474738Z"
    }
   },
   "source": "# Define paths\nDATA_PATH = '../../Dataset [Original]/'\n\n# Load datasets\nhotels_df = pd.read_csv(DATA_PATH + 'hotels.csv')\nreviews_df = pd.read_csv(DATA_PATH + 'reviews.csv')\nusers_df = pd.read_csv(DATA_PATH + 'users.csv')\n\nprint(f\"Hotels Dataset Shape: {hotels_df.shape}\")\nprint(f\"Reviews Dataset Shape: {reviews_df.shape}\")\nprint(f\"Users Dataset Shape: {users_df.shape}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotels Dataset Shape: (25, 13)\n",
      "Reviews Dataset Shape: (50000, 12)\n",
      "Users Dataset Shape: (2000, 6)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 1: Data Cleaning\n",
    "\n",
    "## Description\n",
    "Remove unnecessary columns and handle null values/duplicates to prepare clean datasets for analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.1: Initial Data Exploration\n",
    "\n",
    "Examine the structure and quality of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotels Dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"HOTELS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(hotels_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(hotels_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(hotels_df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", hotels_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews Dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"REVIEWS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(reviews_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(reviews_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(reviews_df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", reviews_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users Dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"USERS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(users_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(users_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(users_df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", users_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.2: Handle Missing Values\n",
    "\n",
    "Identify and handle missing values appropriately for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement missing value handling\n",
    "# Strategy: Analyze each column and decide on appropriate handling (drop, fill, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.3: Handle Duplicate Rows\n",
    "\n",
    "Remove duplicate entries if any exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.4: Remove Unnecessary Columns\n",
    "\n",
    "Identify and remove columns that are not needed for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remove unnecessary columns\n",
    "# Document which columns are removed and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.5: Data Cleaning Summary\n",
    "\n",
    "Summarize the cleaning operations performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print summary of cleaning operations\n",
    "print(\"Cleaned Hotels Dataset Shape:\", hotels_df.shape)\n",
    "print(\"Cleaned Reviews Dataset Shape:\", reviews_df.shape)\n",
    "print(\"Cleaned Users Dataset Shape:\", users_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 2: Data Engineering Questions\n",
    "\n",
    "## Description\n",
    "Analyze the dataset to answer specific business questions with visualizations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 2.1: Question 1 - Which city is best for each traveler type?\n",
    "\n",
    "**Task:** For each traveler type (Solo, Business, Family, Couple), recommend the best city based on the given reviews.\n",
    "\n",
    "**Approach:**\n",
    "- Merge datasets to get city and traveler type information\n",
    "- Calculate average scores per city for each traveler type\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate best city for each traveler type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "- [TODO: Add insights and interpretation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 2.2: Question 2 - Top 3 countries with best value-for-money per age group\n",
    "\n",
    "**Task:** What are the top 3 countries with the best value-for-money score per traveler's age group?\n",
    "\n",
    "**Approach:**\n",
    "- Create age groups from user ages\n",
    "- Calculate average value-for-money scores by country and age group\n",
    "- Identify top 3 countries for each age group\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate top 3 countries per age group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "- [TODO: Add insights and interpretation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 3: Predictive Modeling\n",
    "\n",
    "## Description\n",
    "Develop a statistical ML model or shallow FFNN to predict the country groups in the new column 'country_group'.\n",
    "\n",
    "**Target:** country_group (11 classes)\n",
    "\n",
    "**Features:**\n",
    "- Score-Based Features from the hotel's info and the users' reviews\n",
    "- Features about the user, including their age group, type, and gender\n",
    "- Quality-Based Features representing overall score and value for money\n",
    "\n",
    "**Evaluation Metrics:** Accuracy, Precision, Recall, F1-score\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.1: Create Country Groups\n",
    "\n",
    "Map countries to their respective country groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define country group mapping\n",
    "country_group_mapping = {\n",
    "    'United States': 'North_America',\n",
    "    'Canada': 'North_America',\n",
    "    'Germany': 'Western_Europe',\n",
    "    'France': 'Western_Europe',\n",
    "    'United Kingdom': 'Western_Europe',\n",
    "    'Netherlands': 'Western_Europe',\n",
    "    'Spain': 'Western_Europe',\n",
    "    'Italy': 'Western_Europe',\n",
    "    'Russia': 'Eastern_Europe',\n",
    "    'China': 'East_Asia',\n",
    "    'Japan': 'East_Asia',\n",
    "    'South Korea': 'East_Asia',\n",
    "    'Thailand': 'Southeast_Asia',\n",
    "    'Singapore': 'Southeast_Asia',\n",
    "    'United Arab Emirates': 'Middle_East',\n",
    "    'Turkey': 'Middle_East',\n",
    "    'Egypt': 'Africa',\n",
    "    'Nigeria': 'Africa',\n",
    "    'South Africa': 'Africa',\n",
    "    'Australia': 'Oceania',\n",
    "    'New Zealand': 'Oceania',\n",
    "    'Brazil': 'South_America',\n",
    "    'Argentina': 'South_America',\n",
    "    'India': 'South_Asia',\n",
    "    'Mexico': 'North_America_Mexico'\n",
    "}\n",
    "\n",
    "# TODO: Apply mapping to create country_group column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.2: Feature Engineering\n",
    "\n",
    "Create and select features for the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create age groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge datasets to create feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create score-based features\n",
    "# - score_overall, score_cleanliness, score_comfort, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create quality-based features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encode categorical features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection Justification:**\n",
    "- [TODO: Document which features were selected and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.3: Data Preprocessing\n",
    "\n",
    "Prepare data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into features (X) and target (y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train-test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.4: Model Training\n",
    "\n",
    "Train the classification model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train model(s)\n",
    "# Options: Random Forest, XGBoost, Shallow Neural Network, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection Justification:**\n",
    "- [TODO: Explain why this model was chosen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.5: Model Evaluation\n",
    "\n",
    "Evaluate model performance using accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Analysis:**\n",
    "- [TODO: Analyze model performance and discuss results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.6: Save Model and Processed Data\n",
    "\n",
    "Save the trained model and cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save cleaned dataset with country_group column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 4: Model Explainability\n",
    "\n",
    "## Description\n",
    "Apply explainable AI techniques (SHAP, LIME) to interpret predictions and identify the most influential features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 4.1: SHAP Analysis\n",
    "\n",
    "Use SHAP (SHapley Additive exPlanations) to understand feature importance and contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize SHAP explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate SHAP values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot SHAP summary plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot SHAP feature importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SHAP Analysis Insights:**\n",
    "- [TODO: Interpret SHAP results and explain which features are most influential]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 4.2: LIME Analysis\n",
    "\n",
    "Use LIME (Local Interpretable Model-agnostic Explanations) to explain individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize LIME explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explain individual predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIME Analysis Insights:**\n",
    "- [TODO: Interpret LIME results for sample predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 4.3: Overall Feature Importance Summary\n",
    "\n",
    "Summarize the most influential features across both explainability methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare and summarize feature importance from SHAP and LIME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Findings:**\n",
    "- [TODO: Summarize the most influential features and their impact on predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Inference Function\n",
    "\n",
    "## Description\n",
    "Create a function that takes raw input and returns model predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_country_group(input_data):\n",
    "    \"\"\"\n",
    "    Predicts the country group for given input data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : dict or pd.DataFrame\n",
    "        Input features containing:\n",
    "        - Score-based features (cleanliness, comfort, facilities, etc.)\n",
    "        - User demographics (age_group, gender, traveler_type)\n",
    "        - Quality features (overall_score, value_for_money)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Predicted country group\n",
    "    \"\"\"\n",
    "    # TODO: Implement inference function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test the inference function with sample data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Š Final Summary\n",
    "\n",
    "## Project Completion Checklist\n",
    "\n",
    "- [ ] **Objective 1: Data Cleaning** - Completed\n",
    "- [ ] **Objective 2: Data Engineering Questions** - Completed\n",
    "  - [ ] Question 1: Best city per traveler type\n",
    "  - [ ] Question 2: Top 3 countries per age group for value-for-money\n",
    "- [ ] **Objective 3: Predictive Modeling** - Completed\n",
    "  - [ ] Model trained and evaluated\n",
    "  - [ ] Metrics: Accuracy, Precision, Recall, F1-score\n",
    "- [ ] **Objective 4: Model Explainability** - Completed\n",
    "  - [ ] SHAP analysis\n",
    "  - [ ] LIME analysis\n",
    "- [ ] **Inference Function** - Implemented and tested\n",
    "\n",
    "## Deliverables Status\n",
    "\n",
    "1. âœ… Jupyter Notebook with complete workflow\n",
    "2. âœ… Cleaned dataset with country_group column\n",
    "3. âœ… Report answering data engineering questions\n",
    "4. âœ… Trained predictive model\n",
    "5. âœ… XAI outputs (SHAP/LIME)\n",
    "6. âœ… Inference function\n",
    "\n",
    "---\n",
    "\n",
    "**Submission Deadline:** October 22, 2025 at 11:59 PM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
