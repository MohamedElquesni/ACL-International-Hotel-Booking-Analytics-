{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: International Hotel Booking Analytics\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook implements a comprehensive machine learning pipeline to predict the country group of hotel reviews based on user demographics, hotel characteristics, and review scores.\n",
    "\n",
    "**Dataset:**\n",
    "- Hotels Dataset: 25 hotels\n",
    "- Reviews Dataset: 50,000 reviews\n",
    "- Users Dataset: 2,000 users\n",
    "\n",
    "**Deadline:** October 22, 2025 at 11:59 PM\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:52.590449Z",
     "start_time": "2025-10-10T22:35:51.476589Z"
    }
   },
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Model Explainability\n",
    "import shap\n",
    "# import lime\n",
    "\n",
    "# Database\n",
    "import sqlite3\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:52.670347Z",
     "start_time": "2025-10-10T22:35:52.596356Z"
    }
   },
   "source": "# Define paths\nDATA_PATH = '../../Dataset [Original]/'\n\n# Load datasets\nhotels_df = pd.read_csv(DATA_PATH + 'hotels.csv')\nreviews_df = pd.read_csv(DATA_PATH + 'reviews.csv')\nusers_df = pd.read_csv(DATA_PATH + 'users.csv')\n\nprint(f\"Hotels Dataset Shape: {hotels_df.shape}\")\nprint(f\"Reviews Dataset Shape: {reviews_df.shape}\")\nprint(f\"Users Dataset Shape: {users_df.shape}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotels Dataset Shape: (25, 13)\n",
      "Reviews Dataset Shape: (50000, 12)\n",
      "Users Dataset Shape: (2000, 6)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 1: Data Cleaning\n",
    "\n",
    "## Description\n",
    "Remove unnecessary columns and handle null values/duplicates to prepare clean datasets for analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.1: Initial Data Exploration\n",
    "\n",
    "Examine the structure and quality of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:52.696447Z",
     "start_time": "2025-10-10T22:35:52.679999Z"
    }
   },
   "source": [
    "# Hotels Dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"HOTELS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(hotels_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(hotels_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(hotels_df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", hotels_df.duplicated().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HOTELS DATASET\n",
      "================================================================================\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   hotel_id         hotel_name      city               country  star_rating  \\\n",
       "0         1    The Azure Tower  New York         United States            5   \n",
       "1         2  The Royal Compass    London        United Kingdom            5   \n",
       "2         3    L'Ã‰toile Palace     Paris                France            5   \n",
       "3         4       Kyo-to Grand     Tokyo                 Japan            5   \n",
       "4         5   The Golden Oasis     Dubai  United Arab Emirates            5   \n",
       "\n",
       "       lat       lon  cleanliness_base  comfort_base  facilities_base  \\\n",
       "0  40.7580  -73.9855               9.1           8.8              8.9   \n",
       "1  51.5072   -0.1276               9.0           9.2              8.8   \n",
       "2  48.8566    2.3522               8.8           9.4              8.7   \n",
       "3  35.6895  139.6917               9.6           9.0              9.3   \n",
       "4  25.2769   55.2962               9.3           9.5              9.6   \n",
       "\n",
       "   location_base  staff_base  value_for_money_base  \n",
       "0            9.5         8.6                   8.0  \n",
       "1            9.4         9.0                   7.9  \n",
       "2            9.6         9.3                   8.1  \n",
       "3            8.5         9.5                   8.2  \n",
       "4            8.9         9.4                   8.5  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>cleanliness_base</th>\n",
       "      <th>comfort_base</th>\n",
       "      <th>facilities_base</th>\n",
       "      <th>location_base</th>\n",
       "      <th>staff_base</th>\n",
       "      <th>value_for_money_base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Azure Tower</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>5</td>\n",
       "      <td>40.7580</td>\n",
       "      <td>-73.9855</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Royal Compass</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>5</td>\n",
       "      <td>51.5072</td>\n",
       "      <td>-0.1276</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L'Ã‰toile Palace</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>5</td>\n",
       "      <td>48.8566</td>\n",
       "      <td>2.3522</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kyo-to Grand</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>5</td>\n",
       "      <td>35.6895</td>\n",
       "      <td>139.6917</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Golden Oasis</td>\n",
       "      <td>Dubai</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>5</td>\n",
       "      <td>25.2769</td>\n",
       "      <td>55.2962</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   hotel_id              25 non-null     int64  \n",
      " 1   hotel_name            25 non-null     object \n",
      " 2   city                  25 non-null     object \n",
      " 3   country               25 non-null     object \n",
      " 4   star_rating           25 non-null     int64  \n",
      " 5   lat                   25 non-null     float64\n",
      " 6   lon                   25 non-null     float64\n",
      " 7   cleanliness_base      25 non-null     float64\n",
      " 8   comfort_base          25 non-null     float64\n",
      " 9   facilities_base       25 non-null     float64\n",
      " 10  location_base         25 non-null     float64\n",
      " 11  staff_base            25 non-null     float64\n",
      " 12  value_for_money_base  25 non-null     float64\n",
      "dtypes: float64(8), int64(2), object(3)\n",
      "memory usage: 2.7+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "hotel_id                0\n",
      "hotel_name              0\n",
      "city                    0\n",
      "country                 0\n",
      "star_rating             0\n",
      "lat                     0\n",
      "lon                     0\n",
      "cleanliness_base        0\n",
      "comfort_base            0\n",
      "facilities_base         0\n",
      "location_base           0\n",
      "staff_base              0\n",
      "value_for_money_base    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:52.781040Z",
     "start_time": "2025-10-10T22:35:52.741340Z"
    }
   },
   "source": [
    "# Reviews Dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"REVIEWS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(reviews_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(reviews_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(reviews_df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", reviews_df.duplicated().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REVIEWS DATASET\n",
      "================================================================================\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   review_id  user_id  hotel_id review_date  score_overall  score_cleanliness  \\\n",
       "0          1     1600         1  2022-10-07            8.7                8.6   \n",
       "1          2      432         4  2020-03-24            9.1               10.0   \n",
       "2          3      186        18  2023-12-18            8.8                9.7   \n",
       "3          4     1403        19  2022-06-22            8.9                9.0   \n",
       "4          5     1723        17  2022-07-02            9.1                8.9   \n",
       "\n",
       "   score_comfort  score_facilities  score_location  score_staff  \\\n",
       "0            8.7               8.5             9.0          8.8   \n",
       "1            9.1               9.0             8.6          9.4   \n",
       "2            8.8               8.3             8.7          8.1   \n",
       "3            8.8               8.5             9.6          9.1   \n",
       "4            9.5               9.3             8.3          9.4   \n",
       "\n",
       "   score_value_for_money                                        review_text  \n",
       "0                    8.7  Practice reduce young our because machine. Rec...  \n",
       "1                    8.6  Test cover traditional black. Process tell Mr ...  \n",
       "2                    8.6  Friend million student social study yeah. Grow...  \n",
       "3                    8.3  Huge girl already remain truth behind card. Ap...  \n",
       "4                    8.9  Cover feeling call community serve television ...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>score_overall</th>\n",
       "      <th>score_cleanliness</th>\n",
       "      <th>score_comfort</th>\n",
       "      <th>score_facilities</th>\n",
       "      <th>score_location</th>\n",
       "      <th>score_staff</th>\n",
       "      <th>score_value_for_money</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Practice reduce young our because machine. Rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>432</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>9.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Test cover traditional black. Process tell Mr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>18</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Friend million student social study yeah. Grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1403</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>8.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Huge girl already remain truth behind card. Ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1723</td>\n",
       "      <td>17</td>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Cover feeling call community serve television ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   review_id              50000 non-null  int64  \n",
      " 1   user_id                50000 non-null  int64  \n",
      " 2   hotel_id               50000 non-null  int64  \n",
      " 3   review_date            50000 non-null  object \n",
      " 4   score_overall          50000 non-null  float64\n",
      " 5   score_cleanliness      50000 non-null  float64\n",
      " 6   score_comfort          50000 non-null  float64\n",
      " 7   score_facilities       50000 non-null  float64\n",
      " 8   score_location         50000 non-null  float64\n",
      " 9   score_staff            50000 non-null  float64\n",
      " 10  score_value_for_money  50000 non-null  float64\n",
      " 11  review_text            50000 non-null  object \n",
      "dtypes: float64(7), int64(3), object(2)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "review_id                0\n",
      "user_id                  0\n",
      "hotel_id                 0\n",
      "review_date              0\n",
      "score_overall            0\n",
      "score_cleanliness        0\n",
      "score_comfort            0\n",
      "score_facilities         0\n",
      "score_location           0\n",
      "score_staff              0\n",
      "score_value_for_money    0\n",
      "review_text              0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:52.851469Z",
     "start_time": "2025-10-10T22:35:52.840886Z"
    }
   },
   "source": [
    "# Users Dataset\n",
    "print(\"=\" * 80)\n",
    "print(\"USERS DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(users_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(users_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(users_df.isnull().sum())\n",
    "print(\"\\nDuplicate Rows:\", users_df.duplicated().sum())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "USERS DATASET\n",
      "================================================================================\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user_id user_gender         country age_group traveller_type   join_date\n",
       "0        1      Female  United Kingdom     35-44           Solo  2024-09-29\n",
       "1        2        Male  United Kingdom     25-34           Solo  2023-11-29\n",
       "2        3      Female          Mexico     25-34         Family  2022-04-03\n",
       "3        4        Male           India     35-44         Family  2023-12-02\n",
       "4        5       Other           Japan     25-34           Solo  2021-12-18"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>country</th>\n",
       "      <th>age_group</th>\n",
       "      <th>traveller_type</th>\n",
       "      <th>join_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Solo</td>\n",
       "      <td>2024-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Solo</td>\n",
       "      <td>2023-11-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Family</td>\n",
       "      <td>2022-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>India</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Family</td>\n",
       "      <td>2023-12-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Other</td>\n",
       "      <td>Japan</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Solo</td>\n",
       "      <td>2021-12-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   user_id         2000 non-null   int64 \n",
      " 1   user_gender     2000 non-null   object\n",
      " 2   country         2000 non-null   object\n",
      " 3   age_group       2000 non-null   object\n",
      " 4   traveller_type  2000 non-null   object\n",
      " 5   join_date       2000 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 93.9+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "user_id           0\n",
      "user_gender       0\n",
      "country           0\n",
      "age_group         0\n",
      "traveller_type    0\n",
      "join_date         0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.2: Handle Missing Values\n",
    "\n",
    "Identify and handle missing values appropriately for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:52.950162Z",
     "start_time": "2025-10-10T22:35:52.942250Z"
    }
   },
   "source": "# Check for missing values across all datasets\nprint(\"Missing Values Summary:\")\nprint(\"=\" * 80)\nprint(f\"Hotels Dataset - Total missing values: {hotels_df.isnull().sum().sum()}\")\nprint(f\"Reviews Dataset - Total missing values: {reviews_df.isnull().sum().sum()}\")\nprint(f\"Users Dataset - Total missing values: {users_df.isnull().sum().sum()}\")\nprint(\"\\nâœ“ No missing values found in any dataset - no imputation needed!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Summary:\n",
      "================================================================================\n",
      "Hotels Dataset - Total missing values: 0\n",
      "Reviews Dataset - Total missing values: 0\n",
      "Users Dataset - Total missing values: 0\n",
      "\n",
      "âœ“ No missing values found in any dataset - no imputation needed!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.3: Handle Duplicate Rows\n",
    "\n",
    "Remove duplicate entries if any exist."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.034901Z",
     "start_time": "2025-10-10T22:35:53.009481Z"
    }
   },
   "source": "# Check for duplicate rows across all datasets\nprint(\"Duplicate Rows Summary:\")\nprint(\"=\" * 80)\nprint(f\"Hotels Dataset - Duplicate rows: {hotels_df.duplicated().sum()}\")\nprint(f\"Reviews Dataset - Duplicate rows: {reviews_df.duplicated().sum()}\")\nprint(f\"Users Dataset - Duplicate rows: {users_df.duplicated().sum()}\")\nprint(\"\\nâœ“ No duplicate rows found in any dataset - no removal needed!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows Summary:\n",
      "================================================================================\n",
      "Hotels Dataset - Duplicate rows: 0\n",
      "Reviews Dataset - Duplicate rows: 0\n",
      "Users Dataset - Duplicate rows: 0\n",
      "\n",
      "âœ“ No duplicate rows found in any dataset - no removal needed!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.4: Remove Unnecessary Columns\n",
    "\n",
    "Identify and remove columns that are not needed for analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.050320Z",
     "start_time": "2025-10-10T22:35:53.041533Z"
    }
   },
   "source": "# Remove unnecessary columns from each dataset\n\n# Hotels Dataset\nhotels_columns_to_remove = [\n    'hotel_name',  # Text identifier - not useful for numerical modeling\n    'lat',         # Geographic coordinates - not mentioned in modeling requirements\n    'lon'          # Geographic coordinates - city/country already captured\n]\n# Only drop columns that actually exist\nhotels_to_drop = [col for col in hotels_columns_to_remove if col in hotels_df.columns]\nif hotels_to_drop:\n    hotels_df = hotels_df.drop(columns=hotels_to_drop)\n    print(f\"Hotels Dataset - Removed {len(hotels_to_drop)} columns: {hotels_to_drop}\")\nelse:\n    print(\"Hotels Dataset - No columns to remove (already cleaned or don't exist)\")\n\n# Reviews Dataset\nreviews_columns_to_remove = [\n    'review_id',    # Just an identifier for tracking - no predictive value\n    'review_date',  # Temporal analysis not in scope for Milestone 1\n    'review_text'   # NLP/text analysis not required for this milestone\n]\n# Only drop columns that actually exist\nreviews_to_drop = [col for col in reviews_columns_to_remove if col in reviews_df.columns]\nif reviews_to_drop:\n    reviews_df = reviews_df.drop(columns=reviews_to_drop)\n    print(f\"Reviews Dataset - Removed {len(reviews_to_drop)} columns: {reviews_to_drop}\")\nelse:\n    print(\"Reviews Dataset - No columns to remove (already cleaned or don't exist)\")\n\n# Users Dataset\nusers_columns_to_remove = [\n    'join_date'  # Temporal data not relevant to country group prediction\n]\n# Only drop columns that actually exist\nusers_to_drop = [col for col in users_columns_to_remove if col in users_df.columns]\nif users_to_drop:\n    users_df = users_df.drop(columns=users_to_drop)\n    print(f\"Users Dataset - Removed {len(users_to_drop)} column(s): {users_to_drop}\")\nelse:\n    print(\"Users Dataset - No columns to remove (already cleaned or don't exist)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Remaining Columns:\")\nprint(\"=\"*80)\nprint(f\"\\nHotels ({len(hotels_df.columns)} columns): {list(hotels_df.columns)}\")\nprint(f\"\\nReviews ({len(reviews_df.columns)} columns): {list(reviews_df.columns)}\")\nprint(f\"\\nUsers ({len(users_df.columns)} columns): {list(users_df.columns)}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotels Dataset - Removed 3 columns: ['hotel_name', 'lat', 'lon']\n",
      "Reviews Dataset - Removed 3 columns: ['review_id', 'review_date', 'review_text']\n",
      "Users Dataset - Removed 1 column(s): ['join_date']\n",
      "\n",
      "================================================================================\n",
      "Remaining Columns:\n",
      "================================================================================\n",
      "\n",
      "Hotels (10 columns): ['hotel_id', 'city', 'country', 'star_rating', 'cleanliness_base', 'comfort_base', 'facilities_base', 'location_base', 'staff_base', 'value_for_money_base']\n",
      "\n",
      "Reviews (9 columns): ['user_id', 'hotel_id', 'score_overall', 'score_cleanliness', 'score_comfort', 'score_facilities', 'score_location', 'score_staff', 'score_value_for_money']\n",
      "\n",
      "Users (5 columns): ['user_id', 'user_gender', 'country', 'age_group', 'traveller_type']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 1.5: Data Cleaning Summary\n",
    "\n",
    "Summarize the cleaning operations performed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:39:16.204336Z",
     "start_time": "2025-10-10T22:39:16.199593Z"
    }
   },
   "source": "# Data Cleaning Summary\nprint(\"Data Cleaning Complete!\")\nprint(\"=\"*80)\nprint(\"\\nFinal Dataset Shapes:\")\nprint(f\"  Hotels Dataset:  {hotels_df.shape[0]} rows Ã— {hotels_df.shape[1]} columns\")\nprint(f\"  Reviews Dataset: {reviews_df.shape[0]} rows Ã— {reviews_df.shape[1]} columns\")\nprint(f\"  Users Dataset:   {users_df.shape[0]} rows Ã— {users_df.shape[1]} columns\")\nprint(\"\\nâœ“ All datasets cleaned and ready for analysis\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Complete!\n",
      "================================================================================\n",
      "\n",
      "Final Dataset Shapes:\n",
      "  Hotels Dataset:  25 rows Ã— 10 columns\n",
      "  Reviews Dataset: 50000 rows Ã— 9 columns\n",
      "  Users Dataset:   2000 rows Ã— 5 columns\n",
      "\n",
      "âœ“ All datasets cleaned and ready for analysis\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 2: Data Engineering Questions\n",
    "\n",
    "## Description\n",
    "Analyze the dataset to answer specific business questions with visualizations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 2.1: Question 1 - Which city is best for each traveler type?\n",
    "\n",
    "**Task:** For each traveler type (Solo, Business, Family, Couple), recommend the best city based on the given reviews.\n",
    "\n",
    "**Approach:**\n",
    "- Merge datasets to get city and traveler type information\n",
    "- Calculate average scores per city for each traveler type\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.091406Z",
     "start_time": "2025-10-10T22:35:53.089015Z"
    }
   },
   "source": [
    "# TODO: Merge datasets\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.110461Z",
     "start_time": "2025-10-10T22:35:53.108247Z"
    }
   },
   "source": [
    "# TODO: Calculate best city for each traveler type\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.117474Z",
     "start_time": "2025-10-10T22:35:53.114932Z"
    }
   },
   "source": [
    "# TODO: Visualize results\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "- [TODO: Add insights and interpretation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 2.2: Question 2 - Top 3 countries with best value-for-money per age group\n",
    "\n",
    "**Task:** What are the top 3 countries with the best value-for-money score per traveler's age group?\n",
    "\n",
    "**Approach:**\n",
    "- Create age groups from user ages\n",
    "- Calculate average value-for-money scores by country and age group\n",
    "- Identify top 3 countries for each age group\n",
    "- Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.126263Z",
     "start_time": "2025-10-10T22:35:53.123979Z"
    }
   },
   "source": [
    "# TODO: Create age groups\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.133020Z",
     "start_time": "2025-10-10T22:35:53.130650Z"
    }
   },
   "source": [
    "# TODO: Calculate top 3 countries per age group\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.138812Z",
     "start_time": "2025-10-10T22:35:53.136936Z"
    }
   },
   "source": [
    "# TODO: Visualize results\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "- [TODO: Add insights and interpretation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 3: Predictive Modeling\n",
    "\n",
    "## Description\n",
    "Develop a statistical ML model or shallow FFNN to predict the country groups in the new column 'country_group'.\n",
    "\n",
    "**Target:** country_group (11 classes)\n",
    "\n",
    "**Features:**\n",
    "- Score-Based Features from the hotel's info and the users' reviews\n",
    "- Features about the user, including their age group, type, and gender\n",
    "- Quality-Based Features representing overall score and value for money\n",
    "\n",
    "**Evaluation Metrics:** Accuracy, Precision, Recall, F1-score\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.1: Create Country Groups\n",
    "\n",
    "Map countries to their respective country groups."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.145738Z",
     "start_time": "2025-10-10T22:35:53.143017Z"
    }
   },
   "source": [
    "# Define country group mapping\n",
    "country_group_mapping = {\n",
    "    'United States': 'North_America',\n",
    "    'Canada': 'North_America',\n",
    "    'Germany': 'Western_Europe',\n",
    "    'France': 'Western_Europe',\n",
    "    'United Kingdom': 'Western_Europe',\n",
    "    'Netherlands': 'Western_Europe',\n",
    "    'Spain': 'Western_Europe',\n",
    "    'Italy': 'Western_Europe',\n",
    "    'Russia': 'Eastern_Europe',\n",
    "    'China': 'East_Asia',\n",
    "    'Japan': 'East_Asia',\n",
    "    'South Korea': 'East_Asia',\n",
    "    'Thailand': 'Southeast_Asia',\n",
    "    'Singapore': 'Southeast_Asia',\n",
    "    'United Arab Emirates': 'Middle_East',\n",
    "    'Turkey': 'Middle_East',\n",
    "    'Egypt': 'Africa',\n",
    "    'Nigeria': 'Africa',\n",
    "    'South Africa': 'Africa',\n",
    "    'Australia': 'Oceania',\n",
    "    'New Zealand': 'Oceania',\n",
    "    'Brazil': 'South_America',\n",
    "    'Argentina': 'South_America',\n",
    "    'India': 'South_Asia',\n",
    "    'Mexico': 'North_America_Mexico'\n",
    "}\n",
    "\n",
    "# TODO: Apply mapping to create country_group column\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.2: Feature Engineering\n",
    "\n",
    "Create and select features for the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.151794Z",
     "start_time": "2025-10-10T22:35:53.149789Z"
    }
   },
   "source": [
    "# TODO: Create age groups\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.158172Z",
     "start_time": "2025-10-10T22:35:53.156050Z"
    }
   },
   "source": [
    "# TODO: Merge datasets to create feature set\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.164055Z",
     "start_time": "2025-10-10T22:35:53.162056Z"
    }
   },
   "source": [
    "# TODO: Create score-based features\n",
    "# - score_overall, score_cleanliness, score_comfort, etc.\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.170335Z",
     "start_time": "2025-10-10T22:35:53.168196Z"
    }
   },
   "source": [
    "# TODO: Create quality-based features\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.176345Z",
     "start_time": "2025-10-10T22:35:53.173986Z"
    }
   },
   "source": [
    "# TODO: Encode categorical features\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection Justification:**\n",
    "- [TODO: Document which features were selected and why]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.3: Data Preprocessing\n",
    "\n",
    "Prepare data for model training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.181922Z",
     "start_time": "2025-10-10T22:35:53.179837Z"
    }
   },
   "source": [
    "# TODO: Split data into features (X) and target (y)\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.188434Z",
     "start_time": "2025-10-10T22:35:53.186325Z"
    }
   },
   "source": [
    "# TODO: Train-test split\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.194645Z",
     "start_time": "2025-10-10T22:35:53.192558Z"
    }
   },
   "source": [
    "# TODO: Scale features\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.4: Model Training\n",
    "\n",
    "Train the classification model(s)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.201015Z",
     "start_time": "2025-10-10T22:35:53.198870Z"
    }
   },
   "source": [
    "# TODO: Train model(s)\n",
    "# Options: Random Forest, XGBoost, Shallow Neural Network, etc.\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection Justification:**\n",
    "- [TODO: Explain why this model was chosen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.5: Model Evaluation\n",
    "\n",
    "Evaluate model performance using accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.206453Z",
     "start_time": "2025-10-10T22:35:53.204594Z"
    }
   },
   "source": [
    "# TODO: Make predictions\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.212380Z",
     "start_time": "2025-10-10T22:35:53.210014Z"
    }
   },
   "source": [
    "# TODO: Calculate evaluation metrics\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.218790Z",
     "start_time": "2025-10-10T22:35:53.216751Z"
    }
   },
   "source": [
    "# TODO: Display classification report\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.224734Z",
     "start_time": "2025-10-10T22:35:53.222807Z"
    }
   },
   "source": [
    "# TODO: Plot confusion matrix\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Analysis:**\n",
    "- [TODO: Analyze model performance and discuss results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 3.6: Save Model and Processed Data\n",
    "\n",
    "Save the trained model and cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.230397Z",
     "start_time": "2025-10-10T22:35:53.228311Z"
    }
   },
   "source": [
    "# TODO: Save model\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.236281Z",
     "start_time": "2025-10-10T22:35:53.234289Z"
    }
   },
   "source": [
    "# TODO: Save cleaned dataset with country_group column\n"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Objective 4: Model Explainability\n",
    "\n",
    "## Description\n",
    "Apply explainable AI techniques (SHAP, LIME) to interpret predictions and identify the most influential features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 4.1: SHAP Analysis\n",
    "\n",
    "Use SHAP (SHapley Additive exPlanations) to understand feature importance and contributions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.243112Z",
     "start_time": "2025-10-10T22:35:53.240876Z"
    }
   },
   "source": [
    "# TODO: Initialize SHAP explainer\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.250877Z",
     "start_time": "2025-10-10T22:35:53.248949Z"
    }
   },
   "source": [
    "# TODO: Calculate SHAP values\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.257043Z",
     "start_time": "2025-10-10T22:35:53.254620Z"
    }
   },
   "source": [
    "# TODO: Plot SHAP summary plot\n"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.262956Z",
     "start_time": "2025-10-10T22:35:53.260880Z"
    }
   },
   "source": [
    "# TODO: Plot SHAP feature importance\n"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SHAP Analysis Insights:**\n",
    "- [TODO: Interpret SHAP results and explain which features are most influential]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 4.2: LIME Analysis\n",
    "\n",
    "Use LIME (Local Interpretable Model-agnostic Explanations) to explain individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.269614Z",
     "start_time": "2025-10-10T22:35:53.267341Z"
    }
   },
   "source": [
    "# TODO: Initialize LIME explainer\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.276751Z",
     "start_time": "2025-10-10T22:35:53.274026Z"
    }
   },
   "source": [
    "# TODO: Explain individual predictions\n"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIME Analysis Insights:**\n",
    "- [TODO: Interpret LIME results for sample predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“‹ 4.3: Overall Feature Importance Summary\n",
    "\n",
    "Summarize the most influential features across both explainability methods."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.288898Z",
     "start_time": "2025-10-10T22:35:53.286801Z"
    }
   },
   "source": [
    "# TODO: Compare and summarize feature importance from SHAP and LIME\n"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Findings:**\n",
    "- [TODO: Summarize the most influential features and their impact on predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“¦ Inference Function\n",
    "\n",
    "## Description\n",
    "Create a function that takes raw input and returns model predictions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.295376Z",
     "start_time": "2025-10-10T22:35:53.293010Z"
    }
   },
   "source": [
    "def predict_country_group(input_data):\n",
    "    \"\"\"\n",
    "    Predicts the country group for given input data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : dict or pd.DataFrame\n",
    "        Input features containing:\n",
    "        - Score-based features (cleanliness, comfort, facilities, etc.)\n",
    "        - User demographics (age_group, gender, traveler_type)\n",
    "        - Quality features (overall_score, value_for_money)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Predicted country group\n",
    "    \"\"\"\n",
    "    # TODO: Implement inference function\n",
    "    pass"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T22:35:53.303091Z",
     "start_time": "2025-10-10T22:35:53.300972Z"
    }
   },
   "source": [
    "# TODO: Test the inference function with sample data\n"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ“Š Final Summary\n",
    "\n",
    "## Project Completion Checklist\n",
    "\n",
    "- [ ] **Objective 1: Data Cleaning** - Completed\n",
    "- [ ] **Objective 2: Data Engineering Questions** - Completed\n",
    "  - [ ] Question 1: Best city per traveler type\n",
    "  - [ ] Question 2: Top 3 countries per age group for value-for-money\n",
    "- [ ] **Objective 3: Predictive Modeling** - Completed\n",
    "  - [ ] Model trained and evaluated\n",
    "  - [ ] Metrics: Accuracy, Precision, Recall, F1-score\n",
    "- [ ] **Objective 4: Model Explainability** - Completed\n",
    "  - [ ] SHAP analysis\n",
    "  - [ ] LIME analysis\n",
    "- [ ] **Inference Function** - Implemented and tested\n",
    "\n",
    "## Deliverables Status\n",
    "\n",
    "1. âœ… Jupyter Notebook with complete workflow\n",
    "2. âœ… Cleaned dataset with country_group column\n",
    "3. âœ… Report answering data engineering questions\n",
    "4. âœ… Trained predictive model\n",
    "5. âœ… XAI outputs (SHAP/LIME)\n",
    "6. âœ… Inference function\n",
    "\n",
    "---\n",
    "\n",
    "**Submission Deadline:** October 22, 2025 at 11:59 PM\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
