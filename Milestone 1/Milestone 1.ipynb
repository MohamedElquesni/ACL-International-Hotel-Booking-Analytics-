{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MohamedElquesni/ACL-International-Hotel-Booking-Analytics-/blob/Nadine/Milestone%201/Milestone%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "5ecbbaa32011a5b1"
  },
  {
   "metadata": {
    "id": "15be22039cc67b"
   },
   "cell_type": "markdown",
   "source": [
    "# Milestone 1: International Hotel Booking Analytics\n",
    "## Predicting Hotel Country Groups using Machine Learning (ML)\n",
    "\n",
    "**Team Number:** [90]  \n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Goal:** Build a multi-class classification model to predict the country group of hotels based on user demographics, hotel characteristics, and review scores.\n",
    "\n",
    "**Dataset:**\n",
    "- 50,000 reviews across 25 hotels in 25 countries\n",
    "- 2,000 unique users with demographic information\n",
    "- 11 target country groups\n",
    "\n",
    "**Deliverables:**\n",
    "1. A cleaned dataset after the feature engineering step.\n",
    "2. Data engineering insights, including:\n",
    " - The best city for each traveller type.\n",
    " - The top three countries with the best value-for-money scores per traveller age group.\n",
    "\n",
    "3. A trained classification model (statistical ML or shallow FFNN).\n",
    "4. Model interpretation and explainability through XAI techniques (SHAP and LIME).\n",
    "5. An inference function.\n",
    "\n",
    "---"
   ],
   "id": "15be22039cc67b"
  },
  {
   "cell_type": "markdown",
   "id": "l3zc9ubxxcn",
   "source": [
    "# Section 1: Data Cleaning"
   ],
   "metadata": {
    "id": "l3zc9ubxxcn"
   }
  },
  {
   "metadata": {
    "id": "29f4d60a768f2aa5"
   },
   "cell_type": "markdown",
   "source": [
    "## 1.1 - Importing Libraries"
   ],
   "id": "29f4d60a768f2aa5"
  },
  {
   "metadata": {
    "id": "c8c75190c8840e03"
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ],
   "id": "c8c75190c8840e03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "457ab6f4d5975ae6"
   },
   "cell_type": "markdown",
   "source": [
    "## 1.2 - Loading and Assessing Datasets"
   ],
   "id": "457ab6f4d5975ae6"
  },
  {
   "metadata": {
    "id": "da2b4b6bbc45af6e"
   },
   "cell_type": "markdown",
   "source": [
    "### Hotels Dataset"
   ],
   "id": "da2b4b6bbc45af6e"
  },
  {
   "metadata": {
    "id": "d67cad12cf9b507f"
   },
   "cell_type": "markdown",
   "source": [
    "#### Loading the Hotels Dataset\n"
   ],
   "id": "d67cad12cf9b507f"
  },
  {
   "metadata": {
    "id": "78c0881235ce70aa",
    "outputId": "d659d04c-a1f4-4323-c6d2-9d0e301d9667",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    }
   },
   "cell_type": "code",
   "source": [
    "df_hotels = pd.read_csv('../Dataset [Original]/hotels.csv')\n",
    "df_hotels.head()"
   ],
   "id": "78c0881235ce70aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "f334ac37d1767347"
   },
   "cell_type": "markdown",
   "source": [
    "#### Renaming Hotel Columns --> Hotel_ + Original Column name"
   ],
   "id": "f334ac37d1767347"
  },
  {
   "metadata": {
    "id": "942cd43e249f92a2"
   },
   "cell_type": "code",
   "source": [
    "df_hotels.columns = [\n",
    "    col if col == 'hotel_id' or col == 'hotel_name' else 'hotel_' + col\n",
    "    for col in df_hotels.columns\n",
    "]\n"
   ],
   "id": "942cd43e249f92a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "1e195b3a3c0b4f0"
   },
   "cell_type": "markdown",
   "source": [
    "#### Checking for Null Values"
   ],
   "id": "1e195b3a3c0b4f0"
  },
  {
   "metadata": {
    "id": "86c9e54c7878d44e",
    "outputId": "e4c3691b-5cb0-4d9f-954b-8410929c4463",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    }
   },
   "cell_type": "code",
   "source": [
    "df_hotels.isnull().sum()"
   ],
   "id": "86c9e54c7878d44e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "80fd038b39e4a3d2"
   },
   "cell_type": "markdown",
   "source": [
    "#### Checking for Duplicated Values"
   ],
   "id": "80fd038b39e4a3d2"
  },
  {
   "metadata": {
    "id": "44250c36f1247d35",
    "outputId": "b3e51e74-9ab9-42e8-8960-9358c78d3113",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "df_hotels.duplicated().sum()"
   ],
   "id": "44250c36f1247d35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "844c2dc1ca08fd4f"
   },
   "cell_type": "markdown",
   "source": [
    "### Reviews Dataset"
   ],
   "id": "844c2dc1ca08fd4f"
  },
  {
   "metadata": {
    "id": "c61f1fcfc2b68a95",
    "outputId": "e7e5aa5d-bef1-4bea-b873-c669d3bfd2d4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    }
   },
   "cell_type": "code",
   "source": [
    "df_reviews = pd.read_csv('../Dataset [Original]/reviews.csv')\n",
    "df_reviews.head()"
   ],
   "id": "c61f1fcfc2b68a95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9129802ac37b080c"
   },
   "cell_type": "markdown",
   "source": [
    "#### Renaming Reviews Columns --> Review_ + Original Column name"
   ],
   "id": "9129802ac37b080c"
  },
  {
   "metadata": {
    "id": "2b814f510627729a"
   },
   "cell_type": "code",
   "source": [
    "df_reviews.columns = [\n",
    "    col if col == 'review_id'\n",
    "           or col == 'user_id'\n",
    "           or col == 'hotel_id'\n",
    "           or col == 'review_date'\n",
    "           or col == 'review_text'\n",
    "        else 'review_' + col\n",
    "    for col in df_reviews.columns\n",
    "]\n"
   ],
   "id": "2b814f510627729a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "ae4a33a122340181"
   },
   "cell_type": "markdown",
   "source": [
    "#### Checking for Null Values"
   ],
   "id": "ae4a33a122340181"
  },
  {
   "metadata": {
    "id": "959605430ea81098",
    "outputId": "cd9a3b68-58f9-4002-958e-6adbafa69d8f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    }
   },
   "cell_type": "code",
   "source": [
    "df_reviews.isnull().sum()"
   ],
   "id": "959605430ea81098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "c7d2051cc9e3c256"
   },
   "cell_type": "markdown",
   "source": [
    "#### Checking for Duplicated Values"
   ],
   "id": "c7d2051cc9e3c256"
  },
  {
   "metadata": {
    "id": "865cab3e8172f8df",
    "outputId": "29e72782-d3f9-409e-ea87-49d1230de0a9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "df_reviews.duplicated().sum()"
   ],
   "id": "865cab3e8172f8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "7c8d80b1ce6b9a0d"
   },
   "cell_type": "markdown",
   "source": [
    "### Users Dataset"
   ],
   "id": "7c8d80b1ce6b9a0d"
  },
  {
   "metadata": {
    "id": "923d039f80276f2e",
    "outputId": "37478aaa-d181-4e88-a52a-6f4dfdfd1bfe",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    }
   },
   "cell_type": "code",
   "source": [
    "df_users = pd.read_csv('../Dataset [Original]/users.csv')\n",
    "df_users.head() # This shows the 5 rows"
   ],
   "id": "923d039f80276f2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "1460d25b57366803"
   },
   "cell_type": "markdown",
   "source": [
    "#### Renaming Users Columns --> User_ + Original Column name"
   ],
   "id": "1460d25b57366803"
  },
  {
   "metadata": {
    "id": "6b3c01d093baa02c"
   },
   "cell_type": "code",
   "source": [
    "df_users.columns = [\n",
    "    col if col == 'user_id'\n",
    "        or col == 'user_gender'\n",
    "        else 'user_' + col\n",
    "    for col in df_users.columns\n",
    "]\n"
   ],
   "id": "6b3c01d093baa02c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2873e9b40c517b7f"
   },
   "cell_type": "markdown",
   "source": [
    "#### Checking for Null Values"
   ],
   "id": "2873e9b40c517b7f"
  },
  {
   "metadata": {
    "id": "df35bd0bd7e55dd1",
    "outputId": "26b974b3-d5e4-4856-a16b-16505ab4921e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    }
   },
   "cell_type": "code",
   "source": [
    "df_users.isnull().sum()"
   ],
   "id": "df35bd0bd7e55dd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9d8e3acff57e1f7d"
   },
   "cell_type": "markdown",
   "source": [
    "#### Checking for Duplicated Values"
   ],
   "id": "9d8e3acff57e1f7d"
  },
  {
   "metadata": {
    "id": "2d772189ce05d1e5",
    "outputId": "7a8c4252-4dc2-4c07-f0b6-e0ccb45bca4e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "source": [
    "df_users.duplicated().sum()"
   ],
   "id": "2d772189ce05d1e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8n4trrda6ih",
   "source": [
    "## 1.3 - Merging Datasets"
   ],
   "metadata": {
    "id": "8n4trrda6ih"
   }
  },
  {
   "cell_type": "code",
   "id": "16qtsi5p0z9",
   "source": [
    "# Merge reviews with users on user_id\n",
    "df_merged = pd.merge(df_reviews, df_users, on='user_id', how='left')\n",
    "\n",
    "# Merge the result with hotels on hotel_id\n",
    "df_merged = pd.merge(df_merged, df_hotels, on='hotel_id', how='left')\n",
    "\n",
    "df_merged.head()"
   ],
   "metadata": {
    "id": "16qtsi5p0z9",
    "outputId": "f602dc25-0a24-4e89-d6e0-6a3aed50e0a6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "yyju46d246",
   "source": [
    "df_merged.info()"
   ],
   "metadata": {
    "id": "yyju46d246",
    "outputId": "1ee34d45-c6f8-48dc-d5f6-c556e97e8f76",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 - Dropping Unnecessary Columns"
   ],
   "metadata": {
    "id": "xbFSH6CAlDIs"
   },
   "id": "xbFSH6CAlDIs"
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop unnecessary columns that do not contribute to the predictive modeling task\n",
    "# These columns are either textual, identifiers or dates that add no generalizable value\n",
    "\n",
    "df_merged.drop(\n",
    "    columns=[\n",
    "        'review_date',\n",
    "        'review_text',\n",
    "        'user_join_date',\n",
    "        'hotel_name'\n",
    "    ],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "df_merged.info()\n"
   ],
   "metadata": {
    "id": "SE_a-gOolLjq",
    "outputId": "f9883463-41fe-4b94-9493-99a04f545d73",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "SE_a-gOolLjq",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "izurjlail9",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "izurjlail9"
   }
  },
  {
   "cell_type": "markdown",
   "id": "x9srolp5pmd",
   "source": [
    "## 1.5 - Cleaned Dataset Summary\n",
    "\n",
    "All datasets have been successfully loaded, cleaned, and merged:\n",
    "- No null values found.\n",
    "- No duplicate records.\n",
    "- Columns renamed with prefixes for clarity.\n",
    "- Unnecessary columns were dropped.\n",
    "- Final merged dataset contains 50,000 reviews with complete hotel characteristics and user information\n"
   ],
   "metadata": {
    "id": "x9srolp5pmd"
   }
  },
  {
   "metadata": {
    "id": "6d995c8fe1704d8c"
   },
   "cell_type": "markdown",
   "source": [
    "# Section 2: Data Engineering Questions\n",
    "\n",
    "Using the cleaned and merged dataset, we analyze and visualize the following:\n",
    "\n",
    "1. **Best City for Each Trave;ler Type**\n",
    "   - Identify the city with the highest average review score for each traveler type.\n",
    "\n",
    "2. **Top 3 Countries by Value-for-Money per Age Group**\n",
    "   - Find the top 3 countries with the highest value-for-money score per traveller’s age group."
   ],
   "id": "6d995c8fe1704d8c"
  },
  {
   "metadata": {
    "id": "fb9bfb2d238876c2"
   },
   "cell_type": "markdown",
   "source": [
    "## 2.1 - Best City for Each Traveller Type"
   ],
   "id": "fb9bfb2d238876c2"
  },
  {
   "metadata": {
    "id": "c1299c64fe454b4c"
   },
   "cell_type": "markdown",
   "source": [
    "### Heatmap Analysis"
   ],
   "id": "c1299c64fe454b4c"
  },
  {
   "metadata": {
    "id": "99b8c1786515eda1",
    "outputId": "23a745e5-1001-4a8a-c0ef-6534f5a85c51",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    }
   },
   "cell_type": "code",
   "source": [
    "pivot = pd.pivot_table(\n",
    "        df_merged,\n",
    "        index=\"hotel_city\",\n",
    "        columns=\"user_traveller_type\",\n",
    "        values=\"review_score_overall\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "\n",
    "\n",
    "sns.heatmap(pivot, annot=True, cmap=\"copper\", fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "# Extra GUI enhancements\n",
    "plt.title(\"Average Review Score per City and Traveller Type \", fontsize=14)\n",
    "plt.xlabel(\"Traveller Type\")\n",
    "plt.ylabel(\"City\")\n",
    "plt.show()\n"
   ],
   "id": "99b8c1786515eda1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "54d0649549c4b2cb"
   },
   "cell_type": "markdown",
   "source": [
    "### Insights\n",
    "\n",
    "Using the heatmap visualization, we can observe clear differences in average review scores across traveller types and cities:\n",
    "\n",
    "- **Business travellers:** Dubai achieved the highest average score of **8.97**.\n",
    "- **Couples:** Amsterdam recorded the highest average score of **9.10**.\n",
    "- **Families:** Dubai again stood out with an average score of **9.21**.\n",
    "- **Solo travellers:** Amsterdam had the highest average score of **9.11**."
   ],
   "id": "54d0649549c4b2cb"
  },
  {
   "metadata": {
    "id": "3d99eacbd40f5d9d"
   },
   "cell_type": "markdown",
   "source": [
    "## 2.2 - Top 3 Countries by Value-for-Money per Age Group"
   ],
   "id": "3d99eacbd40f5d9d"
  },
  {
   "metadata": {
    "id": "73294be7819bf89b"
   },
   "cell_type": "markdown",
   "source": [
    "### Heatmap Analysis"
   ],
   "id": "73294be7819bf89b"
  },
  {
   "metadata": {
    "id": "4a630c307de2f148",
    "outputId": "a3162050-7919-49a3-9dfe-60b695f7dd61",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    }
   },
   "cell_type": "code",
   "source": [
    "pivot = pd.pivot_table(\n",
    "    df_merged,\n",
    "    index=\"hotel_country\",\n",
    "    columns=\"user_age_group\",\n",
    "    values=\"review_score_value_for_money\",\n",
    "    aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    pivot,\n",
    "    annot=True,\n",
    "    cmap=\"copper\",\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "# Extra GUI Interface\n",
    "plt.title(\"Average Value-for-Money Score per Country and Age Group\", fontsize=14)\n",
    "plt.xlabel(\"User Age Group\")\n",
    "plt.ylabel(\"Hotel Country\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "4a630c307de2f148",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2a51c8b21678adf"
   },
   "cell_type": "markdown",
   "source": [
    "### Insights\n",
    "\n",
    "Top 3 countries by value-for-money score for each age group:\n",
    "\n",
    "- **18–24:** China (8.71), Netherlands (8.70), Canada (8.66)\n",
    "- **25–34:** China (8.73), Netherlands (8.68), Spain (8.63)\n",
    "- **35–44:** China (8.70), Netherlands (8.69), New Zealand (8.65)\n",
    "- **45–54:** China (8.72), New Zealand (8.67), Netherlands (8.65)\n",
    "- **55+:** Netherlands (8.70), New Zealand (8.63), China (8.60)"
   ],
   "id": "2a51c8b21678adf"
  },
  {
   "cell_type": "markdown",
   "id": "lzcsrv4a8tm",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "lzcsrv4a8tm"
   }
  },
  {
   "metadata": {
    "id": "494e5404653157f8"
   },
   "cell_type": "markdown",
   "source": [
    "# Section 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Objective:** Understand data distributions, correlations, and patterns to inform feature engineering and modeling decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 - Target Variable Analysis"
   ],
   "id": "494e5404653157f8"
  },
  {
   "metadata": {
    "id": "2dd2b6a1b9d06f51"
   },
   "cell_type": "markdown",
   "source": [
    "### Create Target Variable\n",
    "\n",
    "We group the 25 countries into 11 geographic regions (country groups) to create our classification target."
   ],
   "id": "2dd2b6a1b9d06f51"
  },
  {
   "metadata": {
    "id": "6ec64beb990963cc",
    "outputId": "71e5f8bc-7ca7-470e-9160-53bc4a7712fc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a mapping dictionary from country names to geographic regions (country groups)\n",
    "# This groups the 25 countries into 11 regions (country groups) for classification\n",
    "country_to_group = {\n",
    "    # North America\n",
    "    'United States': 'North_America',\n",
    "    'Canada': 'North_America',\n",
    "\n",
    "    # Western Europe\n",
    "    'Germany': 'Western_Europe',\n",
    "    'France': 'Western_Europe',\n",
    "    'United Kingdom': 'Western_Europe',\n",
    "    'Netherlands': 'Western_Europe',\n",
    "    'Spain': 'Western_Europe',\n",
    "    'Italy': 'Western_Europe',\n",
    "\n",
    "    # Eastern Europe\n",
    "    'Russia': 'Eastern_Europe',\n",
    "\n",
    "    # East Asia\n",
    "    'China': 'East_Asia',\n",
    "    'Japan': 'East_Asia',\n",
    "    'South Korea': 'East_Asia',\n",
    "\n",
    "    # Southeast Asia\n",
    "    'Thailand': 'Southeast_Asia',\n",
    "    'Singapore': 'Southeast_Asia',\n",
    "\n",
    "    # Middle East\n",
    "    'United Arab Emirates': 'Middle_East',\n",
    "    'Turkey': 'Middle_East',\n",
    "\n",
    "    # Africa\n",
    "    'Egypt': 'Africa',\n",
    "    'Nigeria': 'Africa',\n",
    "    'South Africa': 'Africa',\n",
    "\n",
    "    # Oceania\n",
    "    'Australia': 'Oceania',\n",
    "    'New Zealand': 'Oceania',\n",
    "\n",
    "    # South America\n",
    "    'Brazil': 'South_America',\n",
    "    'Argentina': 'South_America',\n",
    "\n",
    "    # South Asia\n",
    "    'India': 'South_Asia',\n",
    "\n",
    "    # North America (Mexico separate due to different characteristics)\n",
    "    'Mexico': 'North_America_Mexico'\n",
    "}\n",
    "\n",
    "# Apply the mapping to create our target variable\n",
    "df_merged['country_group'] = df_merged['hotel_country'].map(country_to_group)\n",
    "\n",
    "df_merged.head()\n"
   ],
   "id": "6ec64beb990963cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "nsc4tlaaakn",
   "source": [
    "# Count how many reviews belong to each country group\n",
    "print(\"Distribution of reviews across country groups:\")\n",
    "print(df_merged['country_group'].value_counts().sort_index())"
   ],
   "metadata": {
    "id": "nsc4tlaaakn",
    "outputId": "daf17e8a-7f05-4410-a208-8b5891e223b0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "752f17d4c4f520c7"
   },
   "cell_type": "markdown",
   "source": [
    "### Visualize Target Distribution\n",
    "\n",
    "Now let's visualize the distribution to better understand class imbalance."
   ],
   "id": "752f17d4c4f520c7"
  },
  {
   "cell_type": "code",
   "id": "gbw1ah0t21",
   "source": [
    "# Get the distribution sorted by count (descending)\n",
    "target_dist = df_merged['country_group'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Create a figure with 2 subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# First plot: Bar chart showing counts\n",
    "target_dist.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Distribution of Reviews by Country Group', fontsize=14)\n",
    "axes[0].set_xlabel('Country Group')\n",
    "axes[0].set_ylabel('Number of Reviews')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Second plot: Pie chart showing percentages\n",
    "axes[1].pie(target_dist, labels=target_dist.index, startangle=90)\n",
    "axes[1].set_title('Percentage Distribution by Country Group', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display class imbalance statistics\n",
    "largest_class = target_dist.idxmax()\n",
    "smallest_class = target_dist.idxmin()\n",
    "imbalance_ratio = target_dist.max() / target_dist.min()\n",
    "\n",
    "print(f\"\\nClass Imbalance Analysis:\")\n",
    "print(f\"Largest class: {largest_class} with {target_dist.max()} samples\")\n",
    "print(f\"Smallest class: {smallest_class} with {target_dist.min()} samples\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"\\nThis means the largest class has {imbalance_ratio:.2f}x more samples than the smallest class.\")"
   ],
   "metadata": {
    "id": "gbw1ah0t21",
    "outputId": "4808fec3-7c9c-4641-911e-8c100d728cf8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "552cme8jtoe",
   "source": [
    "---\n",
    "\n",
    "## 3.2 - Numerical Features Analysis\n",
    "\n",
    "Let's analyze the distribution and statistics of numerical features to understand their behavior."
   ],
   "metadata": {
    "id": "552cme8jtoe"
   }
  },
  {
   "cell_type": "code",
   "id": "5dx3en1s9qu",
   "source": [
    "# Identify all numerical columns in the dataset\n",
    "numerical_cols = df_merged.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Total numerical features: {len(numerical_cols)}\\n\")\n",
    "print(\"List of numerical features:\")\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Statistical Summary of Numerical Features:\")\n",
    "print(\"\\n\")\n",
    "df_merged[numerical_cols].describe()"
   ],
   "metadata": {
    "id": "5dx3en1s9qu",
    "outputId": "057eb218-5693-400a-d3d4-6c421bab1ff2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dam1d2sjzra",
   "source": [
    "# Visualize the distribution of numerical features using histograms\n",
    "# This helps us understand if features are normally distributed, skewed, etc.\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(18, 16))\n",
    "axes = axes.ravel()  # Flatten the 2D array to 1D\n",
    "\n",
    "# Plot histogram for each numerical column without ids\n",
    "plot_idx = 0  # Separate counter for axes indexing\n",
    "for idx, col in enumerate(numerical_cols[:19]):\n",
    "    if col == 'review_id' or col == 'user_id' or col == 'hotel_id':\n",
    "        continue\n",
    "    axes[plot_idx].hist(df_merged[col], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[plot_idx].set_title(f'{col}', fontsize=10, fontweight='bold')\n",
    "    axes[plot_idx].set_xlabel('Value', fontsize=9)\n",
    "    axes[plot_idx].set_ylabel('Frequency', fontsize=9)\n",
    "    axes[plot_idx].grid(axis='y', alpha=0.3)   # alpha = transparency\n",
    "    plot_idx += 1  # Increment only when we actually plot\n",
    "\n",
    "plt.suptitle('Distribution of Numerical Features', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "dam1d2sjzra",
    "outputId": "017c99d0-9879-46b4-d8d2-f12080240e67",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99i76n304gi",
   "source": [
    "# Use box plots to detect outliers in numerical features\n",
    "# Box plots show: median (center line), quartiles (box edges), and outliers (dots beyond whiskers)\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(18, 16))\n",
    "axes = axes.ravel()\n",
    "\n",
    "plot_idx = 0  # Separate counter for axes indexing\n",
    "# Create box plot for each numerical column\n",
    "for idx, col in enumerate(numerical_cols[:19]):\n",
    "    if col == 'review_id' or col == 'user_id' or col == 'hotel_id':\n",
    "        continue\n",
    "    axes[plot_idx].boxplot(df_merged[col], vert=True)\n",
    "    axes[plot_idx].set_title(f'{col}', fontsize=10, fontweight='bold')\n",
    "    axes[plot_idx].set_ylabel('Value', fontsize=9)\n",
    "    axes[plot_idx].grid(axis='y', alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "plt.suptitle('Box Plots for Outlier Detection', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Insights:\")\n",
    "print(\"- The box represents the interquartile range (IQR): 25th to 75th percentile\")\n",
    "print(\"- The line inside the box is the median (50th percentile)\")\n",
    "print(\"- Whiskers extend to 1.5 * IQR from the box\")\n",
    "print(\"- Points beyond whiskers are potential outliers\")"
   ],
   "metadata": {
    "id": "99i76n304gi",
    "outputId": "9928becc-deb4-42d8-a435-aac42cf59045",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cbwwmygbuxe",
   "source": [
    "## 3.3 - Correlation Analysis\n",
    "\n",
    "Correlation analysis helps us identify relationships between numerical features. High correlation can indicate:\n",
    "- Redundant features (multicollinearity)\n",
    "- Features that move together\n",
    "- Potential feature combinations"
   ],
   "metadata": {
    "id": "cbwwmygbuxe"
   }
  },
  {
   "cell_type": "code",
   "id": "89cinwbpf9j",
   "source": [
    "# Calculate correlation matrix (Pearson correlation coefficient)\n",
    "# Values range from -1 (perfect negative correlation) to +1 (perfect positive correlation)\n",
    "\n",
    "numerical_cols = [col for col in numerical_cols\n",
    "                           if col not in ['review_id', 'user_id', 'hotel_id']]\n",
    "\n",
    "correlation_matrix = df_merged[numerical_cols].corr()\n",
    "\n",
    "# Visualize using a heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Correlation Coefficient'}\n",
    ")\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find and print highly correlated pairs (correlation > 0.8 or < -0.8)\n",
    "print(\"\\n\")\n",
    "print(\"Highly Correlated Feature Pairs (|correlation| > 0.8):\")\n",
    "print(\"\\n\")\n",
    "print(f\"{'Feature 1':<35} {'Feature 2':<35} {'Correlation':>10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "highly_correlated_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.8:\n",
    "            feat1 = correlation_matrix.columns[i]\n",
    "            feat2 = correlation_matrix.columns[j]\n",
    "            print(f\"{feat1:<35} {feat2:<35} {corr_value:>10.3f}\")\n",
    "            highly_correlated_pairs.append((feat1, feat2, corr_value))\n"
   ],
   "metadata": {
    "id": "89cinwbpf9j",
    "outputId": "76f1f0f3-f8d8-4f9b-85a9-4f40f3439f04",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "mbbo11sm04f",
   "source": [
    "## 3.4 - Categorical Features Analysis\n",
    "\n",
    "Let's examine the distribution of categorical features to understand user demographics and traveller characteristics."
   ],
   "metadata": {
    "id": "mbbo11sm04f"
   }
  },
  {
   "cell_type": "code",
   "id": "aur2pyzgbxi",
   "source": [
    "# Define categorical features to analyze\n",
    "categorical_features = ['user_gender', 'user_age_group', 'user_traveller_type','user_country']\n",
    "\n",
    "print(\"CATEGORICAL FEATURES DISTRIBUTION\")\n",
    "\n",
    "for feat in categorical_features:\n",
    "    print(f\"\\n{feat.upper().replace('_', ' ')}:\")\n",
    "    print(\"-\" * 40)\n",
    "    counts = df_merged[feat].value_counts()\n",
    "\n",
    "    # Display counts and percentages\n",
    "    for value, count in counts.items():\n",
    "        percentage = (count / len(df_merged)) * 100\n",
    "        print(f\"  {value:<30} {count:>6} ({percentage:>5.2f}%)\")\n",
    "\n",
    "    print(f\"\\n  Total unique values: {df_merged[feat].nunique()}\")\n",
    "    print(\"=\"*80)"
   ],
   "metadata": {
    "id": "aur2pyzgbxi",
    "outputId": "71ea564a-9fbb-4849-e07e-45887cf2e56d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "av26a1qgio",
   "source": [
    "# Visualize categorical features using bar charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Create a bar chart for each categorical feature\n",
    "for idx, col in enumerate(categorical_features):\n",
    "    # Get value counts and plot\n",
    "    value_counts = df_merged[col].value_counts()\n",
    "    value_counts.plot(kind='bar', ax=axes[idx], color='teal', alpha=0.7, edgecolor='black')\n",
    "\n",
    "    # Formatting\n",
    "    axes[idx].set_title(f'{col.replace(\"_\", \" \").title()} Distribution',\n",
    "                        fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col.replace('_', ' ').title(), fontsize=11)\n",
    "    axes[idx].set_ylabel('Count', fontsize=11)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # Add value labels on top of bars\n",
    "    for container in axes[idx].containers:\n",
    "        axes[idx].bar_label(container, fmt='%d', padding=3, fontsize=9)\n",
    "\n",
    "plt.suptitle('Distribution of Categorical Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "av26a1qgio",
    "outputId": "181f5bcf-7642-4212-88fe-257e9a945bbd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1zgsa5hatmc",
   "source": [
    "---\n",
    "\n",
    "## 3.5 - EDA Summary & Key Insights\n",
    "\n",
    "Based on the exploratory data analysis, here are the key findings:\n",
    "\n",
    "### Target Variable (country_group)\n",
    " **Class imbalance**: The dataset shows a moderate class imbalance with a 6:1 ratio between largest and smallest country groups.\n",
    "- *Largest class*: Western Europe (most reviews).\n",
    "- *Smallest class*: Eastern Europe (fewest reviews).\n",
    "\n",
    "This imbalance indicates the need for *stratified sampling* during the train/test split to ensure all regions are properly represented in the model.\n",
    "\n",
    "### Data Leakage\n",
    "The features *hotel_city* and *hotel_country* and *all base line scores of hotels* would allow the model to “cheat” by inferring the target from already-known information rather than learning genuine patterns [Since there are 25 unique hotels].\n",
    "\n",
    "###  Numerical Features\n",
    "**Scale**: Most numerical features (review and baseline scores) are on a 0–10 scale.\n",
    "\n",
    "**Distribution**: They are roughly normally distributed with slight right skew (most hotels receive fairly high ratings).\n",
    "\n",
    "**Outliers**: Only a few mild outliers were detected in the box plots.\n",
    "\n",
    "**Variance**: Features show reasonable variance, which is helpful for modeling\n",
    "\n",
    "###  Feature Correlations\n",
    "**Review scores**: Highly correlated with each other (users who rate one aspect highly tend to rate others highly too).\n",
    "\n",
    "**Hotel baseline scores**: Show moderate correlation.\n",
    "\n",
    "###  Categorical Features\n",
    "\n",
    "**User Gender:**\n",
    "- Fairly balanced distribution across Male/Female/Other.\n",
    "- No major gender bias in the dataset.\n",
    "\n",
    "**User Age Group:**\n",
    "- Most users fall in the 25-44 age range\n",
    "- Represents the primary demographic for hotel reviews.\n",
    "\n",
    "**Traveller Type:**\n",
    "- *Couples* and *Families* are the most common (make up about ~60% of reviews).\n",
    "\n",
    "- *Business* and *Solo* travelers are less common but still well-represented.\n",
    "\n"
   ],
   "metadata": {
    "id": "1zgsa5hatmc"
   }
  },
  {
   "cell_type": "markdown",
   "id": "hvdfh9tzd6",
   "source": "---\n\n# Section 4: Feature Engineering\n\n**Objective:** Create deviation features to capture how individual user experiences differ from hotel baselines.\n\n**Approach:** We will use user demographics and deviation features to predict country groups.",
   "metadata": {
    "id": "hvdfh9tzd6"
   }
  },
  {
   "cell_type": "markdown",
   "id": "tilofs15xts",
   "source": "## 4.1 - Deviation Features\n\n**Justification:** Deviation features capture how individual user experiences differ from hotel baselines.\n\n**Formula:** deviation = individual_review_score - hotel_baseline_score\n\nThis indicates:\n- Whether the user's experience was better or worse than the hotel's average\n- How user satisfaction compares to typical hotel performance\n- Individual user preferences relative to hotel standards",
   "metadata": {
    "id": "tilofs15xts"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing the Deviation"
   ],
   "metadata": {
    "id": "MezM_19Es5h6"
   },
   "id": "MezM_19Es5h6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Formula: deviation = individual_review_score - hotel_baseline_score\n",
    "\n",
    "df_merged['deviation_cleanliness'] = (\n",
    "    df_merged['review_score_cleanliness'] - df_merged['hotel_cleanliness_base']\n",
    ")\n",
    "\n",
    "df_merged['deviation_comfort'] = (\n",
    "    df_merged['review_score_comfort'] - df_merged['hotel_comfort_base']\n",
    ")\n",
    "\n",
    "df_merged['deviation_facilities'] = (\n",
    "    df_merged['review_score_facilities'] - df_merged['hotel_facilities_base']\n",
    ")\n",
    "\n",
    "df_merged['deviation_location'] = (\n",
    "    df_merged['review_score_location'] - df_merged['hotel_location_base']\n",
    ")\n",
    "\n",
    "df_merged['deviation_staff'] = (\n",
    "    df_merged['review_score_staff'] - df_merged['hotel_staff_base']\n",
    ")\n",
    "\n",
    "df_merged['deviation_value_for_money'] = (\n",
    "    df_merged['review_score_value_for_money'] - df_merged['hotel_value_for_money_base']\n",
    ")\n",
    "\n",
    "deviation_cols = [col for col in df_merged.columns if col.startswith('deviation_')]\n",
    "print(df_merged[deviation_cols].head())"
   ],
   "id": "bc7b4b1c2364441d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Analysis",
   "metadata": {
    "id": "S7WmWo2itF4F"
   },
   "id": "S7WmWo2itF4F"
  },
  {
   "cell_type": "code",
   "id": "k6yzzpwei2",
   "source": "df_merged[deviation_cols].describe()",
   "metadata": {
    "id": "k6yzzpwei2",
    "outputId": "ef30a66c-27c6-4cbd-dbda-6afc1efb6a5b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d39wzfd3pbv",
   "source": [
    "---\n",
    "\n",
    "# Section 5: Data Preprocessing\n",
    "\n",
    "**Objective:** Prepare data to be ready for our machine learning model through encoding, scaling, and splitting.\n",
    "\n",
    "**Selected Features:**\n",
    "- Categorical: *user_gender*, *user_age_group*, *user_traveller_type* (user demoghraphics)\n",
    "- Numerical: score-based features and the new engineered features *deviation*\n",
    "- Target: *country_group*"
   ],
   "metadata": {
    "id": "d39wzfd3pbv"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.0 - Importing libraries",
   "id": "252b36a9c9252b85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "id": "694631de3a1ae21c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "pyfo1s1s2kl",
   "source": "## 5.1 - Feature Selection",
   "metadata": {
    "id": "pyfo1s1s2kl"
   }
  },
  {
   "cell_type": "code",
   "id": "gans7atkjcc",
   "source": [
    "df_processed = df_merged.copy()\n",
    "\n",
    "selected_columns = [\n",
    "    # Categorical features\n",
    "    'user_gender', 'user_age_group', 'user_traveller_type',\n",
    "\n",
    "    # Review scores (excluding overall)\n",
    "    'review_score_cleanliness', 'review_score_comfort', \n",
    "    'review_score_facilities', 'review_score_location',\n",
    "    'review_score_staff', 'review_score_value_for_money',\n",
    "\n",
    "    # Deviation features\n",
    "    'deviation_cleanliness', 'deviation_comfort',\n",
    "    'deviation_facilities', 'deviation_location',\n",
    "    'deviation_staff', 'deviation_value_for_money',\n",
    "    \n",
    "    # Target\n",
    "    'country_group'\n",
    "]\n",
    "\n",
    "df_processed = df_processed[selected_columns]"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ypp081chvf",
   "source": [
    "## 5.2 - Encoding\n",
    "\n",
    "**Objective**: Converting categorical features into numerical form.\n",
    "\n",
    "*One-hot encoding:* used for unordered (nominal) features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eo2sswfdick",
   "source": [
    "df_processed = pd.get_dummies(\n",
    "    df_processed, \n",
    "    columns=['user_gender', 'user_age_group', 'user_traveller_type'],\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "print(\"After encoding:\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df_processed.columns.tolist())"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5t98yx44gpj",
   "source": "## 5.3 - Split Features and Target",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "jcojkq139x",
   "source": [
    "X = df_processed.drop('country_group', axis=1)\n",
    "y = df_processed['country_group']"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8pvhb8gj56h",
   "source": "## 5.4 - Train-Test-Validation Split\n\nSplit the data into 70% training, 15% validation, and 15% test sets using stratified sampling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "b2ozbomk2y",
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# split 30% into 15% val and 15% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Dataset Split:\")\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Val:   {X_val.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dejsoihj3ep",
   "source": [
    "## 5.5 - Encode Target Variable\n",
    "\n",
    "Convert country_group labels to numerical format using LabelEncoder."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "rbs1r4nnjf",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Class Mapping:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {class_name}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5pl38vwj46b",
   "source": "---\n\n# Section 6: Model Development\n\n**Objective:** Train and compare multiple classification models to predict country groups.\n\nWe will train 4 different models:\n1. Logistic Regression (baseline linear model)\n2. Random Forest (ensemble tree-based)\n3. XGBoost (gradient boosted trees)\n4. Shallow Neural Network (deep learning)\n\n## 6.1 - Import Required Libraries",
   "metadata": {
    "id": "5pl38vwj46b"
   }
  },
  {
   "cell_type": "code",
   "id": "npr4yxw8m5j",
   "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(\"Libraries imported successfully!\")",
   "metadata": {
    "id": "npr4yxw8m5j"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "254or12c7u",
   "source": "## 6.2 - Model 1: Logistic Regression\n\nA linear model that serves as our baseline. Uses one-vs-rest strategy for multi-class classification.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "exwt78j6ute",
   "source": "print(\"Training Logistic Regression...\")\n\n# Initialize with class_weight to handle imbalance\nlr_model = LogisticRegression(\n    max_iter=1000,\n    class_weight='balanced',\n    random_state=42,\n    n_jobs=-1\n)\n\n# Train on training set\nlr_model.fit(X_train, y_train)\n\n# Predict on validation set\ny_val_pred_lr = lr_model.predict(X_val)\n\n# Calculate accuracy\nlr_accuracy = accuracy_score(y_val, y_val_pred_lr)\n\nprint(f\"Logistic Regression Validation Accuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\nprint(\"Model trained successfully!\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ccshtydti",
   "source": "## 6.3 - Model 2: Random Forest\n\nAn ensemble of decision trees that votes on the final prediction. Good at capturing non-linear patterns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dolk596httl",
   "source": "print(\"Training Random Forest...\")\n\n# Initialize with balanced class weights\nrf_model = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=20,\n    min_samples_split=5,\n    min_samples_leaf=2,\n    class_weight='balanced',\n    random_state=42,\n    n_jobs=-1\n)\n\n# Train on training set\nrf_model.fit(X_train, y_train)\n\n# Predict on validation set\ny_val_pred_rf = rf_model.predict(X_val)\n\n# Calculate accuracy\nrf_accuracy = accuracy_score(y_val, y_val_pred_rf)\n\nprint(f\"Random Forest Validation Accuracy: {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\")\nprint(\"Model trained successfully!\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "iya7qc539c",
   "source": "## 6.4 - Model 3: XGBoost\n\nGradient boosted trees that build sequentially, with each tree correcting errors of previous trees. Often the best performer for tabular data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "a9qrh635jgc",
   "source": "print(\"Training XGBoost...\")\n\n# Calculate scale_pos_weight for imbalanced classes\n# This helps XGBoost handle the 6:1 class imbalance\nfrom sklearn.utils.class_weight import compute_sample_weight\nsample_weights = compute_sample_weight('balanced', y_train)\n\n# Initialize XGBoost\nxgb_model = XGBClassifier(\n    n_estimators=100,\n    max_depth=6,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    n_jobs=-1,\n    eval_metric='mlogloss'\n)\n\n# Train with sample weights to handle imbalance\nxgb_model.fit(X_train, y_train_encoded, sample_weight=sample_weights)\n\n# Predict on validation set\ny_val_pred_xgb = xgb_model.predict(X_val)\n\n# Convert predictions back to class names\ny_val_pred_xgb_labels = label_encoder.inverse_transform(y_val_pred_xgb)\n\n# Calculate accuracy\nxgb_accuracy = accuracy_score(y_val, y_val_pred_xgb_labels)\n\nprint(f\"XGBoost Validation Accuracy: {xgb_accuracy:.4f} ({xgb_accuracy*100:.2f}%)\")\nprint(\"Model trained successfully!\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0hy2kz020c6u",
   "source": "## 6.5 - Model 4: Shallow Neural Network\n\nA feedforward neural network with 2 hidden layers. Can learn complex non-linear patterns through activation functions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "duqtgqkabgw",
   "source": "print(\"Building and training Neural Network...\")\n\n# Build shallow neural network\nnn_model = keras.Sequential([\n    keras.layers.Input(shape=(X_train.shape[1],)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(11, activation='softmax')  # 11 country groups\n])\n\n# Compile model\nnn_model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Display model architecture\nnn_model.summary()\n\n# Train model (with early stopping to prevent overfitting)\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\nhistory = nn_model.fit(\n    X_train, y_train_encoded,\n    validation_data=(X_val, y_val_encoded),\n    epochs=50,\n    batch_size=32,\n    callbacks=[early_stop],\n    verbose=0\n)\n\n# Evaluate on validation set\nval_loss, val_accuracy = nn_model.evaluate(X_val, y_val_encoded, verbose=0)\n\nprint(f\"\\nNeural Network Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\nprint(\"Model trained successfully!\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7i5kcwti2zv",
   "source": "## 6.6 - Model Comparison\n\nCompare all 4 models on validation set to identify the best performer.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "q9mufxdtdk",
   "source": "# Create comparison dataframe\nresults = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost', 'Neural Network'],\n    'Validation Accuracy': [lr_accuracy, rf_accuracy, xgb_accuracy, val_accuracy],\n    'Type': ['Linear', 'Tree Ensemble', 'Gradient Boosting', 'Deep Learning']\n})\n\n# Sort by accuracy\nresults = results.sort_values('Validation Accuracy', ascending=False)\n\nprint(\"=\"*70)\nprint(\"MODEL COMPARISON - VALIDATION SET\")\nprint(\"=\"*70)\nprint(results.to_string(index=False))\nprint(\"=\"*70)\n\n# Visualize comparison\nplt.figure(figsize=(10, 6))\nbars = plt.bar(results['Model'], results['Validation Accuracy'], \n               color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])\n\n# Add value labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height,\n             f'{height:.2%}',\n             ha='center', va='bottom', fontweight='bold')\n\nplt.xlabel('Model', fontsize=12)\nplt.ylabel('Validation Accuracy', fontsize=12)\nplt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\nplt.xticks(rotation=15)\nplt.ylim(0, max(results['Validation Accuracy']) * 1.15)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Identify best model\nbest_model_name = results.iloc[0]['Model']\nbest_accuracy = results.iloc[0]['Validation Accuracy']\n\nprint(f\"\\nBest Model: {best_model_name}\")\nprint(f\"Best Validation Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "i6mf3f8hxg"
   },
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Section 7: Model Evaluation\n",
    "\n",
    "**Objective:** Evaluate and compare all models using accuracy, precision, recall, and F1-score.\n",
    "\n",
    "## 7.1 - Model Comparison\n",
    "\n",
    "TODO: Evaluate all models on test set and create comparison table"
   ],
   "id": "fd8bdfbdc7b212b"
  },
  {
   "cell_type": "code",
   "id": "tle95ttmi2",
   "source": [
    "# TODO: Model evaluation\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "#\n",
    "# models = {\n",
    "#     'Logistic Regression': lr_model,\n",
    "#     'Random Forest': rf_model,\n",
    "#     'XGBoost': xgb_model,\n",
    "#     'Neural Network': nn_model\n",
    "# }\n",
    "#\n",
    "# results = []\n",
    "# for name, model in models.items():\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     results.append({\n",
    "#         'Model': name,\n",
    "#         'Accuracy': accuracy_score(y_test, y_pred),\n",
    "#         'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "#         'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "#         'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
    "#     })\n",
    "#\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df)\n",
    "#\n",
    "# # Confusion matrix for best model\n",
    "# best_model = rf_model  # Choose your best\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "#\n",
    "# # Classification report\n",
    "# print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "id": "tle95ttmi2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "lmbkrjast4",
   "source": [
    "---\n",
    "\n",
    "# Section 8: Model Explainability (XAI)\n",
    "\n",
    "**Objective:** Use SHAP and LIME to explain model predictions and identify important features.\n",
    "\n",
    "## 8.1 - SHAP Analysis\n",
    "\n",
    "TODO: Global and local explanations using SHAP"
   ],
   "metadata": {
    "id": "lmbkrjast4"
   }
  },
  {
   "cell_type": "code",
   "id": "61msjxr4vsy",
   "source": [
    "# TODO: SHAP analysis\n",
    "# import shap\n",
    "#\n",
    "# # Initialize explainer (use TreeExplainer for tree-based models)\n",
    "# explainer = shap.TreeExplainer(best_model)\n",
    "# shap_values = explainer.shap_values(X_test)\n",
    "#\n",
    "# # Global feature importance\n",
    "# shap.summary_plot(shap_values, X_test)\n",
    "# shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "#\n",
    "# # Local explanations (pick 3-5 instances)\n",
    "# for i in [0, 10, 50]:\n",
    "#     shap.force_plot(explainer.expected_value, shap_values[i], X_test.iloc[i])\n",
    "#     shap.waterfall_plot(shap.Explanation(values=shap_values[i],\n",
    "#                                          base_values=explainer.expected_value,\n",
    "#                                          data=X_test.iloc[i]))"
   ],
   "metadata": {
    "id": "61msjxr4vsy"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2flxt2lkutt",
   "source": [
    "## 8.2 - LIME Analysis\n",
    "\n",
    "TODO: Local instance explanations using LIME"
   ],
   "metadata": {
    "id": "2flxt2lkutt"
   }
  },
  {
   "cell_type": "code",
   "id": "e7sybe880r",
   "source": [
    "# TODO: LIME analysis\n",
    "# import lime\n",
    "# import lime.lime_tabular\n",
    "#\n",
    "# # Initialize explainer\n",
    "# explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "#     X_train.values,\n",
    "#     feature_names=X_train.columns,\n",
    "#     class_names=['North_America', 'Western_Europe', ...],  # all 11 classes\n",
    "#     mode='classification'\n",
    "# )\n",
    "#\n",
    "# # Explain same instances as SHAP for comparison\n",
    "# for idx in [0, 10, 50]:\n",
    "#     exp = explainer.explain_instance(X_test.iloc[idx].values,\n",
    "#                                       best_model.predict_proba)\n",
    "#     exp.show_in_notebook()\n",
    "#     exp.as_pyplot_figure()"
   ],
   "metadata": {
    "id": "e7sybe880r"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "hpf975oovf",
   "source": [
    "---\n",
    "\n",
    "# Section 9: Inference Function\n",
    "\n",
    "**Objective:** Create a deployable function that accepts raw input and returns predictions in natural language.\n",
    "\n",
    "TODO: Build inference function that preprocesses input and returns human-readable predictions"
   ],
   "metadata": {
    "id": "hpf975oovf"
   }
  },
  {
   "cell_type": "code",
   "id": "16mg89r8bqhi",
   "source": [
    "# TODO: Create inference function\n",
    "# def predict_country_group(user_gender, user_age_group, user_traveller_type,\n",
    "#                           user_country, review_score_overall,\n",
    "#                           review_score_cleanliness, review_score_comfort,\n",
    "#                           review_score_facilities, review_score_location,\n",
    "#                           review_score_staff, review_score_value_for_money,\n",
    "#                           hotel_cleanliness_base, hotel_comfort_base,\n",
    "#                           hotel_facilities_base, hotel_location_base,\n",
    "#                           hotel_staff_base, hotel_value_for_money_base):\n",
    "#     \"\"\"\n",
    "#     Predicts the country group of a hotel based on user and hotel features.\n",
    "#\n",
    "#     Returns:\n",
    "#         str: Predicted country group in natural language\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # 1. Create input dataframe\n",
    "#     input_data = pd.DataFrame({\n",
    "#         'user_gender': [user_gender],\n",
    "#         'user_age_group': [user_age_group],\n",
    "#         # ... add all features\n",
    "#     })\n",
    "#\n",
    "#     # 2. Apply same preprocessing (encoding, scaling, feature engineering)\n",
    "#     # ... your preprocessing code here\n",
    "#\n",
    "#     # 3. Make prediction\n",
    "#     prediction = best_model.predict(processed_input)[0]\n",
    "#\n",
    "#     # 4. Convert to natural language\n",
    "#     country_group_map = {\n",
    "#         'North_America': 'North America (United States, Canada)',\n",
    "#         'Western_Europe': 'Western Europe (Germany, France, UK, Netherlands, Spain, Italy)',\n",
    "#         # ... rest of mappings\n",
    "#     }\n",
    "#\n",
    "#     return country_group_map[prediction]\n",
    "#\n",
    "# # Test with examples\n",
    "# example_1 = predict_country_group(\n",
    "#     user_gender='Male',\n",
    "#     user_age_group='25-34',\n",
    "#     user_traveller_type='Business',\n",
    "#     # ... provide all parameters\n",
    "# )\n",
    "# print(f\"Prediction: {example_1}\")"
   ],
   "metadata": {
    "id": "16mg89r8bqhi"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "include_colab_link": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
